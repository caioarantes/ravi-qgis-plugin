{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import pandas as pd\n",
    "\n",
    "ee.Initialize()\n",
    "ee.Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = \"C:/Users/pc/My Drive/2025/Uni/TCC/Shapes/contorno_area_total/contorno_area_total.shp\"\n",
    "\n",
    "# Check if the path is a .zip file\n",
    "if shapefile_path.endswith('.zip'):\n",
    "    # Try to read shapefile from a zip archive\n",
    "    try:\n",
    "        # Check if the .zip file exists and open it\n",
    "        with zipfile.ZipFile(shapefile_path, 'r') as zip_ref:\n",
    "            zip_ref.printdir()  # Optional: Print contents of the zip to debug\n",
    "            # Try to find the .shp file inside the zip\n",
    "            shapefile_found = False\n",
    "            for file in zip_ref.namelist():\n",
    "                if file.endswith('.shp'):\n",
    "                    shapefile_found = True\n",
    "                    shapefile_within_zip = file\n",
    "                    break\n",
    "\n",
    "            if shapefile_found:\n",
    "                # Read shapefile directly from the zip file\n",
    "                oi = gpd.read_file(f'zip://{shapefile_path}/{shapefile_within_zip}')\n",
    "                print(f\"Successfully loaded shapefile from {shapefile_path}.\")\n",
    "            else:\n",
    "                print(\"No .shp file found inside the zip archive.\")\n",
    "                #\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading shapefile from zip archive: {e}\")\n",
    "        #\n",
    "else:\n",
    "    # If not a .zip, assume it is a regular shapefile\n",
    "    try:\n",
    "        # Read the shapefile normally\n",
    "        aoi = gpd.read_file(shapefile_path)\n",
    "        print(f\"Successfully loaded shapefile from {shapefile_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading shapefile: {e}\")\n",
    "\n",
    "\n",
    "# After loading, check if the GeoDataFrame is not empty\n",
    "if not aoi.empty:\n",
    "    # If the GeoDataFrame contains multiple geometries, dissolve them into one\n",
    "    if len(aoi) > 1:\n",
    "        aoi = aoi.dissolve()\n",
    "\n",
    "    # Extract the first geometry from the dissolved GeoDataFrame\n",
    "    geometry = aoi.geometry.iloc[0]\n",
    "\n",
    "    # Check if the geometry is a Polygon or MultiPolygon\n",
    "    if geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "        # Convert the geometry to GeoJSON format\n",
    "        geojson = geometry.__geo_interface__\n",
    "\n",
    "        # Remove the third dimension from the coordinates if it exists\n",
    "        if geojson['type'] == 'Polygon':\n",
    "            geojson['coordinates'] = [list(map(lambda coord: coord[:2], ring)) for ring in geojson['coordinates']]\n",
    "        elif geojson['type'] == 'MultiPolygon':\n",
    "            geojson['coordinates'] = [[list(map(lambda coord: coord[:2], ring)) for ring in polygon] for polygon in geojson['coordinates']]\n",
    "\n",
    "        # Create an Earth Engine geometry object from the GeoJSON coordinates\n",
    "        ee_geometry = ee.Geometry(geojson)\n",
    "\n",
    "        # Convert the Earth Engine geometry to a Feature\n",
    "        feature = ee.Feature(ee_geometry)\n",
    "\n",
    "        # Create a FeatureCollection with the feature\n",
    "        aoi = ee.FeatureCollection([feature])\n",
    "\n",
    "        print(\"AOI defined successfully.\")\n",
    "\n",
    "        # check_next_button()\n",
    "    else:\n",
    "        \n",
    "        print(\"The geometry is not a valid type (Polygon or MultiPolygon).\")\n",
    "else:\n",
    "    print(\"The shapefile does not contain any geometries.\")        #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates for filtering the image collection\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "inicio = '2024-01-11'\n",
    "final = '2025-01-11'\n",
    "nuvem = 40\n",
    "\n",
    "# Load the Sentinel-2 image collection and filter by date, location, and cloud coverage\n",
    "sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "    .filterDate(inicio, final) \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', nuvem)) \\\n",
    "    .map(lambda image: image.set('date', image.date().format('YYYY-MM-dd')))\n",
    "\n",
    "# Get the number of images in the collection\n",
    "count = sentinel2.size().getInfo()\n",
    "print(f\"Number of images in collection: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original timestamps from the sentinel2 image collection\n",
    "original_timestamps = sentinel2.aggregate_array('system:time_start').getInfo()\n",
    "\n",
    "# Convert timestamps to formatted dates and times\n",
    "formatted_dates_times = [datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M') for ts in original_timestamps]\n",
    "\n",
    "# Print the formatted dates and times\n",
    "print(formatted_dates_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Aggregate timestamps from the ImageCollection\n",
    "original_timestamps = sentinel2.aggregate_array('system:time_start').getInfo()\n",
    "\n",
    "# Step 2: Convert timestamps to formatted dates\n",
    "formatted_dates = [datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d') for ts in original_timestamps]\n",
    "\n",
    "# Step 3: Identify unique dates and map them back to the original timestamps\n",
    "df = pd.DataFrame(list(zip(original_timestamps, formatted_dates)), columns=['timestamp', 'date'])\n",
    "first_timestamps_per_date = df.groupby('date')['timestamp'].min().tolist()\n",
    "\n",
    "# Step 4: Filter the collection to include only the first image for each unique date\n",
    "filtered_collection = sentinel2.filter(\n",
    "    ee.Filter.inList('system:time_start', ee.List(first_timestamps_per_date))\n",
    ")\n",
    "\n",
    "# Step 5: Inspect the results\n",
    "print(f\"Number of first images (one per day): {filtered_collection.size().getInfo()}\")\n",
    "#print(filtered_collection.first().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_collection.aggregate_array('date').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_list_selection = ['2024-01-14',\n",
    " '2024-01-24',\n",
    " '2024-02-05',\n",
    " '2024-02-08',\n",
    " '2024-02-23',\n",
    " '2024-02-25']\n",
    "\n",
    "# Step 1: Filter the collection to include only images with dates in Date_list_selection\n",
    "new_filtered_collection = filtered_collection.filter(\n",
    "    ee.Filter.inList('date', Date_list_selection)\n",
    ")\n",
    "\n",
    "# Step 2: Inspect the results\n",
    "print(f\"Number of images matching Date_list_selection: {new_filtered_collection.size().getInfo()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_list_selection = ['2024-01-24']\n",
    "\n",
    "# Step 1: Filter the collection to include only images with dates in Date_list_selection\n",
    "uniqueday_collection = filtered_collection.filter(\n",
    "    ee.Filter.inList('date', Date_list_selection)\n",
    ")\n",
    "\n",
    "# Step 2: Inspect the results\n",
    "print(f\"Number of images matching Date_list_selection: {new_filtered_collection.size().getInfo()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = uniqueday_collection.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clip image to AOI\n",
    "first_image = first_image.clip(aoi)\n",
    "\n",
    "# Get the acquisition date and define download region\n",
    "region = aoi.geometry().bounds().getInfo()['coordinates']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_image = first_image.normalizedDifference(['B8', 'B4']).rename('NDVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate download URL\n",
    "try:\n",
    "    url = first_image.getDownloadUrl({\n",
    "        'scale': 10,\n",
    "        'region': region,\n",
    "        'format': 'GeoTIFF'\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(f\"Failed to generate download URL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the path to save the downloaded image\n",
    "download_path = 'C:/Users/pc/Downloads/first_image_ndvi.tif'\n",
    "\n",
    "# Download the image from the URL\n",
    "try:\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(download_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Image successfully downloaded to {download_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while downloading the image: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
