{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ee.Authenticate(authorization_code: Optional[str] = None, quiet: Optional[bool] = None, code_verifier: Optional[str] = None, auth_mode: Optional[str] = None, scopes: Optional[Sequence[str]] = None, force: bool = False) -> Optional[bool]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ee\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import pandas as pd\n",
    "\n",
    "ee.Initialize()\n",
    "ee.Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded shapefile from C:/Users/pc/My Drive/2025/Uni/TCC/Shapes/contorno_area_total/contorno_area_total.shp.\n",
      "AOI defined successfully.\n"
     ]
    }
   ],
   "source": [
    "shapefile_path = \"C:/Users/pc/My Drive/2025/Uni/TCC/Shapes/contorno_area_total/contorno_area_total.shp\"\n",
    "\n",
    "# Check if the path is a .zip file\n",
    "if shapefile_path.endswith('.zip'):\n",
    "    # Try to read shapefile from a zip archive\n",
    "    try:\n",
    "        # Check if the .zip file exists and open it\n",
    "        with zipfile.ZipFile(shapefile_path, 'r') as zip_ref:\n",
    "            zip_ref.printdir()  # Optional: Print contents of the zip to debug\n",
    "            # Try to find the .shp file inside the zip\n",
    "            shapefile_found = False\n",
    "            for file in zip_ref.namelist():\n",
    "                if file.endswith('.shp'):\n",
    "                    shapefile_found = True\n",
    "                    shapefile_within_zip = file\n",
    "                    break\n",
    "\n",
    "            if shapefile_found:\n",
    "                # Read shapefile directly from the zip file\n",
    "                oi = gpd.read_file(f'zip://{shapefile_path}/{shapefile_within_zip}')\n",
    "                print(f\"Successfully loaded shapefile from {shapefile_path}.\")\n",
    "            else:\n",
    "                print(\"No .shp file found inside the zip archive.\")\n",
    "                #\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading shapefile from zip archive: {e}\")\n",
    "        #\n",
    "else:\n",
    "    # If not a .zip, assume it is a regular shapefile\n",
    "    try:\n",
    "        # Read the shapefile normally\n",
    "        aoi = gpd.read_file(shapefile_path)\n",
    "        print(f\"Successfully loaded shapefile from {shapefile_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading shapefile: {e}\")\n",
    "\n",
    "\n",
    "# After loading, check if the GeoDataFrame is not empty\n",
    "if not aoi.empty:\n",
    "    # If the GeoDataFrame contains multiple geometries, dissolve them into one\n",
    "    if len(aoi) > 1:\n",
    "        aoi = aoi.dissolve()\n",
    "\n",
    "    # Extract the first geometry from the dissolved GeoDataFrame\n",
    "    geometry = aoi.geometry.iloc[0]\n",
    "\n",
    "    # Check if the geometry is a Polygon or MultiPolygon\n",
    "    if geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "        # Convert the geometry to GeoJSON format\n",
    "        geojson = geometry.__geo_interface__\n",
    "\n",
    "        # Remove the third dimension from the coordinates if it exists\n",
    "        if geojson['type'] == 'Polygon':\n",
    "            geojson['coordinates'] = [list(map(lambda coord: coord[:2], ring)) for ring in geojson['coordinates']]\n",
    "        elif geojson['type'] == 'MultiPolygon':\n",
    "            geojson['coordinates'] = [[list(map(lambda coord: coord[:2], ring)) for ring in polygon] for polygon in geojson['coordinates']]\n",
    "\n",
    "        # Create an Earth Engine geometry object from the GeoJSON coordinates\n",
    "        ee_geometry = ee.Geometry(geojson)\n",
    "\n",
    "        # Convert the Earth Engine geometry to a Feature\n",
    "        feature = ee.Feature(ee_geometry)\n",
    "\n",
    "        # Create a FeatureCollection with the feature\n",
    "        aoi = ee.FeatureCollection([feature])\n",
    "\n",
    "        print(\"AOI defined successfully.\")\n",
    "\n",
    "        # check_next_button()\n",
    "    else:\n",
    "        \n",
    "        print(\"The geometry is not a valid type (Polygon or MultiPolygon).\")\n",
    "else:\n",
    "    print(\"The shapefile does not contain any geometries.\")        #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates for filtering the image collection\n",
    "inicio = '2022-01-01'\n",
    "final = '2023-12-31'\n",
    "nuvem ='40'\n",
    "\n",
    "# Define the start and end dates for filtering the image collection\n",
    "startDate = '2022-01-01'\n",
    "endDate = '2023-12-31'\n",
    "\n",
    "# Load the Sentinel-2 image collection and filter by date, location, and cloud coverage\n",
    "sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "    .filterDate(startDate, endDate) \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "\n",
    "\n",
    "mask = True\n",
    "if mask:\n",
    "    def mask_cloud_and_shadows(image):\n",
    "        # Check if the cloud probability and snow probability bands are available\n",
    "        band_names = image.bandNames()\n",
    "        has_cloud_prob = band_names.contains('MSK_CLDPRB')\n",
    "        has_snow_prob = band_names.contains('MSK_SNWPRB')\n",
    "\n",
    "        # Create masks based on the availability of the bands\n",
    "        cloud_mask = ee.Image(1) if not has_cloud_prob else image.select('MSK_CLDPRB').lt(1)\n",
    "        snow_mask = ee.Image(1) if not has_snow_prob else image.select('MSK_SNWPRB').lt(1)\n",
    "\n",
    "        # Scene classification layer\n",
    "        scl = image.select('SCL')\n",
    "        shadow_mask = scl.neq(3)  # Shadow class\n",
    "        cirrus_mask = scl.neq(10)  # Cirrus class\n",
    "\n",
    "        # Combine all masks\n",
    "        mask = cloud_mask.And(snow_mask).And(shadow_mask).And(cirrus_mask)\n",
    "        return image.updateMask(mask)\n",
    "\n",
    "    # Apply the cloud and shadow mask function to the image collection\n",
    "    sentinel = sentinel2.map(mask_cloud_and_shadows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images before coverage filtering: 297\n",
      "Number of images with >= 90.0% AOI coverage: 278\n"
     ]
    }
   ],
   "source": [
    "#Coverage Ratio Function\n",
    "# -------------------------------\n",
    "aoi_geometry = aoi.first().geometry()\n",
    "aoi_area = aoi_geometry.area()\n",
    "\n",
    "coverage_threshold = 0.9\n",
    "\n",
    "def calculate_coverage_ratio(image):\n",
    "    \"\"\"\n",
    "    Calculates the ratio of the AOI area covered by the image.\n",
    "    \n",
    "    Args:\n",
    "        image (ee.Image): The Sentinel-2 image.\n",
    "    \n",
    "    Returns:\n",
    "        ee.Image: The original image with an added 'coverage_ratio' property.\n",
    "    \"\"\"\n",
    "    # Compute the intersection geometry between AOI and image footprint\n",
    "    intersection = aoi_geometry.intersection(image.geometry(), ee.ErrorMargin(1))\n",
    "    \n",
    "    # Calculate the area of the intersection\n",
    "    intersection_area = intersection.area()\n",
    "    \n",
    "    # Calculate the coverage ratio (intersection area / AOI area)\n",
    "    coverage_ratio = intersection_area.divide(aoi_area)\n",
    "    \n",
    "    # Set the coverage ratio as a property of the image\n",
    "    return image.set('coverage_ratio', coverage_ratio)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Apply Coverage Ratio Calculation\n",
    "# -------------------------------\n",
    "\n",
    "# Map the coverage ratio function over the Sentinel-2 collection\n",
    "sentinel2_with_ratio = sentinel2.map(calculate_coverage_ratio)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: Filter Based on Coverage Ratio\n",
    "# -------------------------------\n",
    "\n",
    "# Define a filter to keep images with coverage_ratio >= coverage_threshold\n",
    "coverage_filter = ee.Filter.gte('coverage_ratio', coverage_threshold)\n",
    "\n",
    "# Apply the filter to get the final collection\n",
    "fully_covering_images = sentinel2_with_ratio.filter(coverage_filter)\n",
    "\n",
    "# Get the number of images before filtering\n",
    "initial_count = sentinel2.size().getInfo()\n",
    "\n",
    "# Get the number of images after coverage filtering\n",
    "filtered_count = fully_covering_images.size().getInfo()\n",
    "\n",
    "print(f\"Number of images before coverage filtering: {initial_count}\")\n",
    "print(f\"Number of images with >= {coverage_threshold*100}% AOI coverage: {filtered_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentine2 = filtered_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  average_index\n",
      "0    2022-01-19       0.713293\n",
      "1    2022-01-19       0.710188\n",
      "2    2022-01-21       0.865844\n",
      "3    2022-01-21       0.865615\n",
      "4    2022-01-26       0.833051\n",
      "..          ...            ...\n",
      "292  2023-12-20       0.591922\n",
      "293  2023-12-25       0.771918\n",
      "294  2023-12-25       0.771704\n",
      "295  2023-12-27       0.804468\n",
      "296  2023-12-27       0.803665\n",
      "\n",
      "[297 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the vegetation index calculation\n",
    "vegetation_index = 'NDVI'\n",
    "\n",
    "def calculate_index(image):\n",
    "    if vegetation_index == 'NDVI':\n",
    "        index_image = image.normalizedDifference(['B8', 'B4']).rename('index')\n",
    "    elif vegetation_index == 'EVI':\n",
    "        index_image = image.expression(\n",
    "            '2.5 * ((NIR / 10000 - RED / 10000) / (NIR / 10000 + 6 * RED / 10000 - 7.5 * BLUE / 10000 + 1))', {\n",
    "                'NIR': image.select('B8'),\n",
    "                'RED': image.select('B4'),\n",
    "                'BLUE': image.select('B2')\n",
    "            }\n",
    "        ).rename('index')\n",
    "    elif vegetation_index == 'SAVI':\n",
    "        L = 0.5\n",
    "        index_image = image.expression(\n",
    "            '(1 + L) * ((NIR / 10000) - (RED / 10000)) / ((NIR / 10000) + (RED / 10000) + L)', {\n",
    "                'NIR': image.select('B8'),\n",
    "                'RED': image.select('B4'),\n",
    "                'L': L\n",
    "            }\n",
    "        ).rename('index')\n",
    "    elif vegetation_index == 'GCI':\n",
    "        index_image = image.expression(\n",
    "            'NIR / GREEN - 1', {\n",
    "                'NIR': image.select('B8'),\n",
    "                'GREEN': image.select('B3')\n",
    "            }\n",
    "        ).rename('index')\n",
    "    elif vegetation_index == 'GNDVI':\n",
    "        index_image = image.normalizedDifference(['B8', 'B3']).rename('index')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported vegetation index: {vegetation_index}\")\n",
    "\n",
    "    # Calculate mean value for the index over the buffered AOI\n",
    "    mean_index = index_image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi,  # Use the buffered AOI\n",
    "        scale=10,\n",
    "        bestEffort=True\n",
    "    ).get('index')\n",
    "    \n",
    "    return image.set({'date': image.date().format('YYYY-MM-dd'), 'mean_index': mean_index})\n",
    "\n",
    "# Map the calculation and filter results\n",
    "result = sentinel2.map(calculate_index).filter(ee.Filter.notNull(['mean_index']))\n",
    "dates = result.aggregate_array('date').getInfo()\n",
    "mean_indices = result.aggregate_array('mean_index').getInfo()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "if dates and mean_indices:\n",
    "    avg_index_values = [{'date': date, 'average_index': index} for date, index in zip(dates, mean_indices)]\n",
    "    df = pd.DataFrame(avg_index_values)\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  average_index\n",
      "0    2022-01-19       0.713913\n",
      "1    2022-01-19       0.710806\n",
      "2    2022-01-21       0.868187\n",
      "3    2022-01-21       0.867953\n",
      "4    2022-01-26       0.834943\n",
      "..          ...            ...\n",
      "292  2023-12-20       0.594253\n",
      "293  2023-12-25       0.775591\n",
      "294  2023-12-25       0.775375\n",
      "295  2023-12-27       0.808138\n",
      "296  2023-12-27       0.807319\n",
      "\n",
      "[297 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the geometry from the FeatureCollection\n",
    "aoi_geometry = aoi.geometry()\n",
    "\n",
    "# Buffer the AOI geometry inward by 10 meters (adjust distance as needed)\n",
    "buffer_distance = -10  # Negative value shrinks the geometry inward\n",
    "aoi_buffered = aoi_geometry.buffer(buffer_distance)\n",
    "\n",
    "# Define the vegetation index calculation\n",
    "vegetation_index = 'NDVI'\n",
    "vegetation_index = 'NDVI'\n",
    "\n",
    "def calculate_index(image):\n",
    "    if vegetation_index == 'NDVI':\n",
    "        index_image = image.normalizedDifference(['B8', 'B4']).rename('index')\n",
    "    elif vegetation_index == 'EVI':\n",
    "        index_image = image.expression(\n",
    "            '2.5 * ((NIR / 10000 - RED / 10000) / (NIR / 10000 + 6 * RED / 10000 - 7.5 * BLUE / 10000 + 1))', {\n",
    "                'NIR': image.select('B8'),\n",
    "                'RED': image.select('B4'),\n",
    "                'BLUE': image.select('B2')\n",
    "            }\n",
    "        ).rename('index')\n",
    "    elif vegetation_index == 'SAVI':\n",
    "        L = 0.5\n",
    "        index_image = image.expression(\n",
    "            '(1 + L) * ((NIR / 10000) - (RED / 10000)) / ((NIR / 10000) + (RED / 10000) + L)', {\n",
    "                'NIR': image.select('B8'),\n",
    "                'RED': image.select('B4'),\n",
    "                'L': L\n",
    "            }\n",
    "        ).rename('index')\n",
    "    elif vegetation_index == 'GCI':\n",
    "        index_image = image.expression(\n",
    "            'NIR / GREEN - 1', {\n",
    "                'NIR': image.select('B8'),\n",
    "                'GREEN': image.select('B3')\n",
    "            }\n",
    "        ).rename('index')\n",
    "    elif vegetation_index == 'GNDVI':\n",
    "        index_image = image.normalizedDifference(['B8', 'B3']).rename('index')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported vegetation index: {vegetation_index}\")\n",
    "\n",
    "    # Calculate mean value for the index over the buffered AOI\n",
    "    mean_index = index_image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi_buffered,  # Use the buffered AOI\n",
    "        scale=10,\n",
    "        bestEffort=True\n",
    "    ).get('index')\n",
    "    \n",
    "    return image.set({'date': image.date().format('YYYY-MM-dd'), 'mean_index': mean_index})\n",
    "\n",
    "# Apply calculations to the existing Sentinel-2 collection\n",
    "result = sentinel2.map(calculate_index).filter(ee.Filter.notNull(['mean_index']))\n",
    "dates = result.aggregate_array('date').getInfo()\n",
    "mean_indices = result.aggregate_array('mean_index').getInfo()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "if dates and mean_indices:\n",
    "    avg_index_values = [{'date': date, 'average_index': index} for date, index in zip(dates, mean_indices)]\n",
    "    df = pd.DataFrame(avg_index_values)\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
